{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834919fb-b7f4-4d6d-804f-0a60a35284e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59af08cc-df82-44b0-bbab-347d7e5d35ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import einops\n",
    "\n",
    "\n",
    "\n",
    "class TemporalFilter(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels,\n",
    "        kernel_size,\n",
    "        srate,\n",
    "        fmin=None,\n",
    "        freq=10,\n",
    "        bandwidth=30,\n",
    "        margin_bandwidth=25,\n",
    "        fmin_variety = 12,\n",
    "        margin_fmin = 4,\n",
    "        seed=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.srate = srate\n",
    "        self.fmin= fmin\n",
    "        self.fmin_variety = fmin_variety\n",
    "        self.margin_fmin = margin_fmin\n",
    "        self.margin_bandwidth = margin_bandwidth\n",
    "        self.bandwidth = bandwidth\n",
    "        self.freq = freq\n",
    "        \n",
    "        if self.kernel_size%2 == 0:\n",
    "            self.register_buffer('_scale', torch.arange(-self.kernel_size//2, self.kernel_size//2 + 1) / self.srate)\n",
    "        else:\n",
    "            self.register_buffer('_scale', torch.arange(-self.kernel_size//2 + 1, self.kernel_size//2 + 1) / self.srate)\n",
    "\n",
    "        if seed is None:\n",
    "            seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "            \n",
    "        if self.bandwidth is None:\n",
    "            coef_bandwidth = self._create_parameters_bandwidth(self.n_channels, seed)\n",
    "            self.coef_bandwidth = nn.Parameter(coef_bandwidth)\n",
    "        else:\n",
    "            if not isinstance(bandwidth, torch.Tensor):\n",
    "                bandwidth = torch.tensor(bandwidth, dtype=torch.float32).reshape((1,))\n",
    "            assert bandwidth.shape[0] in (1, self.n_channels)\n",
    "            if bandwidth.shape[0] != self.n_channels:\n",
    "                bandwidth = bandwidth.repeat(self.n_channels)\n",
    "            self.register_buffer('_bandwidth', bandwidth)\n",
    "\n",
    "        if self.fmin is None:\n",
    "            coef_fmin = self._create_parameters_fmin(self.n_channels, seed)\n",
    "            self.coef_fmin = nn.Parameter(coef_fmin)\n",
    "        else:\n",
    "            if not isinstance(fmin, torch.Tensor):\n",
    "                fmin = torch.tensor(fmin, dtype=torch.float32).reshape((1,))\n",
    "            assert fmin.shape[0] in (1, self.n_channels)\n",
    "            if fmin.shape[0] != self.n_channels:\n",
    "                fmin = fmin.repeat(self.n_channels)\n",
    "            self.register_buffer('_fmin', fmin)\n",
    "        \n",
    "        if self.freq != None:\n",
    "            if not isinstance(freq, torch.Tensor):\n",
    "                freq = torch.tensor(freq, dtype=torch.float32).reshape((1,))\n",
    "            assert freq.shape[0] in (1, self.n_channels)\n",
    "            if freq.shape[0] != self.n_channels:\n",
    "                freq = freq.repeat(self.n_channels)\n",
    "            self.register_buffer('_freq', freq)\n",
    "    \n",
    "\n",
    "    def _create_parameters_bandwidth(self, n_coef, seed):\n",
    "        \n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(seed+1)\n",
    "        coef = torch.rand(size=(n_coef,), generator=generator) * self.margin_bandwidth\n",
    "        \n",
    "        return coef\n",
    "\n",
    "    def _create_parameters_fmin(self, n_coef, seed):\n",
    "        \n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(seed+1)\n",
    "        coef = torch.rand(size=(n_coef,), generator=generator)*self.fmin_variety+self.margin_fmin\n",
    "        \n",
    "        return coef\n",
    "    \n",
    "    def _create_frequencies(self):\n",
    "        \n",
    "        if self.bandwidth is None:\n",
    "            bandwidth = self.coef_bandwidth\n",
    "        else:\n",
    "            bandwidth = self._bandwidth\n",
    "            \n",
    "        if self.fmin is None:\n",
    "            fmin = self.coef_fmin\n",
    "        else:\n",
    "            fmin = self._fmin\n",
    "\n",
    "\n",
    "        if self.freq != None:\n",
    "            freq = self._freq\n",
    "        else:\n",
    "            freq = fmin + bandwidth/2\n",
    "\n",
    "        freq_low = fmin\n",
    "        freq_high = fmin + bandwidth\n",
    "\n",
    "        return bandwidth, freq_low, freq_high, freq\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc58ba-a005-4e18-99cf-8bb81b6dc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SincLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='1d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)\n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,-1)))\n",
    "\n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1)), freq_high.reshape((-1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * _scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * _scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "    \n",
    "                                     \n",
    "class SincLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)         \n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,1,-1)))\n",
    "                                     \n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1,1)), freq_high.reshape((-1,1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * _scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * _scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "                                     \n",
    "    \n",
    "    \n",
    "    \n",
    "class SincHilbertLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='1d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=True)   \n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,-1)))\n",
    "        self.hilbert = HilbertLayer()\n",
    "\n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1)), freq_high.reshape((-1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * _scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * _scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            \n",
    "        if not return_filtered:\n",
    "            x = self.hilbert(x)\n",
    "            x = torch.abs(x)\n",
    "        x = x[...,self.pad.padding_hilbert:-self.pad.padding_hilbert]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SincHilbertLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=True)\n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,-1)))\n",
    "        self.hilbert = HilbertLayer()\n",
    "\n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1,1)), freq_high.reshape((-1,1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * self._scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * self._scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            \n",
    "        if not return_filtered:\n",
    "            x = self.hilbert(x)\n",
    "            x = torch.abs(x)\n",
    "        x = x[...,self.pad.padding_hilbert:-self.pad.padding_hilbert]\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class WaveletLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)     \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1)), bandwidth.reshape((-1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * torch.cos(2*math.pi * freq * _scale)\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "                            \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "\n",
    "    \n",
    "class WaveletLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)     \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1,1)), bandwidth.reshape((-1,1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * torch.cos(2*math.pi * freq * _scale)\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "                            \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class ComplexWaveletLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='1d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)    \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1)), bandwidth.reshape((-1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * (torch.exp(1j*2*math.pi * freq * _scale) - torch.exp(-0.5*(2*math.pi * freq)**2))\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "          \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        \n",
    "        if return_filtered:\n",
    "            x = F.conv1d(x, filt.real, groups=self.in_channels, padding='valid')\n",
    "        else:\n",
    "            x = x.to(torch.complex64)\n",
    "            x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            x = torch.abs(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ComplexWaveletLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)    \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1,1)), bandwidth.reshape((-1,1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * (torch.exp(1j*2*math.pi * freq * _scale) - torch.exp(-0.5*(2*math.pi * freq)**2))\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "          \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        \n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        if return_filtered:\n",
    "            x = F.conv2d(x, filt.real, groups=self.in_channels, padding='valid')\n",
    "        else:\n",
    "            x = x.to(torch.complex64)\n",
    "            x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            x = torch.abs(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a468947-1c6c-4c06-b867-3605afe842cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense', \n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "\\\\\n",
    "def EEGNet_SSVEP(nb_classes = 12, Chans = 8, Samples = 256, \n",
    "             dropoutRate = 0.5, kernLength = 256, F1 = 96, \n",
    "             D = 1, F2 = 96, dropoutType = 'Dropout'):\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "def EEGNet_old(nb_classes, Chans = 64, Samples = 128, regRate = 0.0001,\n",
    "           dropoutRate = 0.25, kernels = [(2, 32), (8, 4)], strides = (2, 4)):\n",
    "\n",
    "    input_main   = Input((Chans, Samples))\n",
    "    layer1       = Conv2D(16, (Chans, 1), input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_regularizer = l1_l2(l1=regRate, l2=regRate))(input_main)\n",
    "    layer1       = BatchNormalization()(layer1)\n",
    "    layer1       = Activation('elu')(layer1)\n",
    "    layer1       = Dropout(dropoutRate)(layer1)\n",
    "    \n",
    "    permute_dims = 2, 1, 3\n",
    "    permute1     = Permute(permute_dims)(layer1)\n",
    "    \n",
    "    layer2       = Conv2D(4, kernels[0], padding = 'same', \n",
    "                            kernel_regularizer=l1_l2(l1=0.0, l2=regRate),\n",
    "                            strides = strides)(permute1)\n",
    "    layer2       = BatchNormalization()(layer2)\n",
    "    layer2       = Activation('elu')(layer2)\n",
    "    layer2       = Dropout(dropoutRate)(layer2)\n",
    "    \n",
    "    layer3       = Conv2D(4, kernels[1], padding = 'same',\n",
    "                            kernel_regularizer=l1_l2(l1=0.0, l2=regRate),\n",
    "                            strides = strides)(layer2)\n",
    "    layer3       = BatchNormalization()(layer3)\n",
    "    layer3       = Activation('elu')(layer3)\n",
    "    layer3       = Dropout(dropoutRate)(layer3)\n",
    "    \n",
    "    flatten      = Flatten(name = 'flatten')(layer3)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "def DeepConvNet(nb_classes, Chans = 64, Samples = 256,\n",
    "                dropoutRate = 0.5):\n",
    "\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(25, (Chans, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "\n",
    "# need these for ShallowConvNet\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "\n",
    "def ShallowConvNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n",
    "\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(40, (1, 13), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(40, (Chans, 1), use_bias=False, \n",
    "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n",
    "    block1       = Activation(log)(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
