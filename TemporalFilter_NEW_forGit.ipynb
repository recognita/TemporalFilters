{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834919fb-b7f4-4d6d-804f-0a60a35284e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense', \n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "\\\\\n",
    "def EEGNet_SSVEP(nb_classes = 12, Chans = 8, Samples = 256, \n",
    "             dropoutRate = 0.5, kernLength = 256, F1 = 96, \n",
    "             D = 1, F2 = 96, dropoutType = 'Dropout'):\n",
    "    \"\"\" SSVEP Variant of EEGNet, as used in [1]. \n",
    "\n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer\n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution.\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "      \n",
    "      \n",
    "    [1]. Waytowich, N. et. al. (2018). Compact Convolutional Neural Networks\n",
    "    for Classification of Asynchronous Steady-State Visual Evoked Potentials.\n",
    "    Journal of Neural Engineering vol. 15(6). \n",
    "    http://iopscience.iop.org/article/10.1088/1741-2552/aae5d8\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (Chans, Samples, 1),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.))(block1)\n",
    "    block1       = BatchNormalization()(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4))(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization()(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8))(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "def EEGNet_old(nb_classes, Chans = 64, Samples = 128, regRate = 0.0001,\n",
    "           dropoutRate = 0.25, kernels = [(2, 32), (8, 4)], strides = (2, 4)):\n",
    "    \"\"\" Keras Implementation of EEGNet_v1 (https://arxiv.org/abs/1611.08024v2)\n",
    "\n",
    "    This model is the original EEGNet model proposed on arxiv\n",
    "            https://arxiv.org/abs/1611.08024v2\n",
    "    \n",
    "    with a few modifications: we use striding instead of max-pooling as this \n",
    "    helped slightly in classification performance while also providing a \n",
    "    computational speed-up. \n",
    "    \n",
    "    Note that we no longer recommend the use of this architecture, as the new\n",
    "    version of EEGNet performs much better overall and has nicer properties.\n",
    "    \n",
    "    Inputs:\n",
    "        \n",
    "        nb_classes     : total number of final categories\n",
    "        Chans, Samples : number of EEG channels and samples, respectively\n",
    "        regRate        : regularization rate for L1 and L2 regularizations\n",
    "        dropoutRate    : dropout fraction\n",
    "        kernels        : the 2nd and 3rd layer kernel dimensions (default is \n",
    "                         the [2, 32] x [8, 4] configuration)\n",
    "        strides        : the stride size (note that this replaces the max-pool\n",
    "                         used in the original paper)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples))\n",
    "    layer1       = Conv2D(16, (Chans, 1), input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_regularizer = l1_l2(l1=regRate, l2=regRate))(input_main)\n",
    "    layer1       = BatchNormalization()(layer1)\n",
    "    layer1       = Activation('elu')(layer1)\n",
    "    layer1       = Dropout(dropoutRate)(layer1)\n",
    "    \n",
    "    permute_dims = 2, 1, 3\n",
    "    permute1     = Permute(permute_dims)(layer1)\n",
    "    \n",
    "    layer2       = Conv2D(4, kernels[0], padding = 'same', \n",
    "                            kernel_regularizer=l1_l2(l1=0.0, l2=regRate),\n",
    "                            strides = strides)(permute1)\n",
    "    layer2       = BatchNormalization()(layer2)\n",
    "    layer2       = Activation('elu')(layer2)\n",
    "    layer2       = Dropout(dropoutRate)(layer2)\n",
    "    \n",
    "    layer3       = Conv2D(4, kernels[1], padding = 'same',\n",
    "                            kernel_regularizer=l1_l2(l1=0.0, l2=regRate),\n",
    "                            strides = strides)(layer2)\n",
    "    layer3       = BatchNormalization()(layer3)\n",
    "    layer3       = Activation('elu')(layer3)\n",
    "    layer3       = Dropout(dropoutRate)(layer3)\n",
    "    \n",
    "    flatten      = Flatten(name = 'flatten')(layer3)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense')(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "\n",
    "\n",
    "def DeepConvNet(nb_classes, Chans = 64, Samples = 256,\n",
    "                dropoutRate = 0.5):\n",
    "    \"\"\" Keras implementation of the Deep Convolutional Network as described in\n",
    "    Schirrmeister et. al. (2017), Human Brain Mapping.\n",
    "    \n",
    "    This implementation assumes the input is a 2-second EEG signal sampled at \n",
    "    128Hz, as opposed to signals sampled at 250Hz as described in the original\n",
    "    paper. We also perform temporal convolutions of length (1, 5) as opposed\n",
    "    to (1, 10) due to this sampling rate difference. \n",
    "    \n",
    "    Note that we use the max_norm constraint on all convolutional layers, as \n",
    "    well as the classification layer. We also change the defaults for the\n",
    "    BatchNormalization layer. We used this based on a personal communication \n",
    "    with the original authors.\n",
    "    \n",
    "                      ours        original paper\n",
    "    pool_size        1, 2        1, 3\n",
    "    strides          1, 2        1, 3\n",
    "    conv filters     1, 5        1, 10\n",
    "    \n",
    "    Note that this implementation has not been verified by the original \n",
    "    authors. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(25, (1, 5), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(25, (Chans, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "  \n",
    "    block2       = Conv2D(50, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block2)\n",
    "    block2       = Dropout(dropoutRate)(block2)\n",
    "    \n",
    "    block3       = Conv2D(100, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block2)\n",
    "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block3)\n",
    "    block3       = Activation('elu')(block3)\n",
    "    block3       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block3)\n",
    "    block3       = Dropout(dropoutRate)(block3)\n",
    "    \n",
    "    block4       = Conv2D(200, (1, 5),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(block3)\n",
    "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block4)\n",
    "    block4       = Activation('elu')(block4)\n",
    "    block4       = MaxPooling2D(pool_size=(1, 2), strides=(1, 2))(block4)\n",
    "    block4       = Dropout(dropoutRate)(block4)\n",
    "    \n",
    "    flatten      = Flatten()(block4)\n",
    "    \n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n",
    "\n",
    "\n",
    "# need these for ShallowConvNet\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n",
    "\n",
    "\n",
    "def ShallowConvNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n",
    "    \"\"\" Keras implementation of the Shallow Convolutional Network as described\n",
    "    in Schirrmeister et. al. (2017), Human Brain Mapping.\n",
    "    \n",
    "    Assumes the input is a 2-second EEG signal sampled at 128Hz. Note that in \n",
    "    the original paper, they do temporal convolutions of length 25 for EEG\n",
    "    data sampled at 250Hz. We instead use length 13 since the sampling rate is \n",
    "    roughly half of the 250Hz which the paper used. The pool_size and stride\n",
    "    in later layers is also approximately half of what is used in the paper.\n",
    "    \n",
    "    Note that we use the max_norm constraint on all convolutional layers, as \n",
    "    well as the classification layer. We also change the defaults for the\n",
    "    BatchNormalization layer. We used this based on a personal communication \n",
    "    with the original authors.\n",
    "    \n",
    "                     ours        original paper\n",
    "    pool_size        1, 35       1, 75\n",
    "    strides          1, 7        1, 15\n",
    "    conv filters     1, 13       1, 25    \n",
    "    \n",
    "    Note that this implementation has not been verified by the original \n",
    "    authors. We do note that this implementation reproduces the results in the\n",
    "    original paper with minor deviations. \n",
    "    \"\"\"\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(40, (1, 13), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(40, (Chans, 1), use_bias=False, \n",
    "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.9)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n",
    "    block1       = Activation(log)(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59af08cc-df82-44b0-bbab-347d7e5d35ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import einops\n",
    "\n",
    "\n",
    "\n",
    "class TemporalFilter(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels,\n",
    "        kernel_size,\n",
    "        srate,\n",
    "        fmin=None,\n",
    "        freq=10,\n",
    "        bandwidth=30,\n",
    "        margin_bandwidth=25,\n",
    "        fmin_variety = 12,\n",
    "        margin_fmin = 4,\n",
    "        seed=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.srate = srate\n",
    "        self.fmin= fmin\n",
    "        self.fmin_variety = fmin_variety\n",
    "        self.margin_fmin = margin_fmin\n",
    "        self.margin_bandwidth = margin_bandwidth\n",
    "        self.bandwidth = bandwidth\n",
    "        self.freq = freq\n",
    "        \n",
    "        if self.kernel_size%2 == 0:\n",
    "            self.register_buffer('_scale', torch.arange(-self.kernel_size//2, self.kernel_size//2 + 1) / self.srate)\n",
    "        else:\n",
    "            self.register_buffer('_scale', torch.arange(-self.kernel_size//2 + 1, self.kernel_size//2 + 1) / self.srate)\n",
    "\n",
    "        if seed is None:\n",
    "            seed = int(torch.empty((), dtype=torch.int64).random_().item())\n",
    "            \n",
    "        if self.bandwidth is None:\n",
    "            coef_bandwidth = self._create_parameters_bandwidth(self.n_channels, seed)\n",
    "            self.coef_bandwidth = nn.Parameter(coef_bandwidth)\n",
    "        else:\n",
    "            if not isinstance(bandwidth, torch.Tensor):\n",
    "                bandwidth = torch.tensor(bandwidth, dtype=torch.float32).reshape((1,))\n",
    "            assert bandwidth.shape[0] in (1, self.n_channels)\n",
    "            if bandwidth.shape[0] != self.n_channels:\n",
    "                bandwidth = bandwidth.repeat(self.n_channels)\n",
    "            self.register_buffer('_bandwidth', bandwidth)\n",
    "\n",
    "        if self.fmin is None:\n",
    "            coef_fmin = self._create_parameters_fmin(self.n_channels, seed)\n",
    "            self.coef_fmin = nn.Parameter(coef_fmin)\n",
    "        else:\n",
    "            if not isinstance(fmin, torch.Tensor):\n",
    "                fmin = torch.tensor(fmin, dtype=torch.float32).reshape((1,))\n",
    "            assert fmin.shape[0] in (1, self.n_channels)\n",
    "            if fmin.shape[0] != self.n_channels:\n",
    "                fmin = fmin.repeat(self.n_channels)\n",
    "            self.register_buffer('_fmin', fmin)\n",
    "        \n",
    "        if self.freq != None:\n",
    "            if not isinstance(freq, torch.Tensor):\n",
    "                freq = torch.tensor(freq, dtype=torch.float32).reshape((1,))\n",
    "            assert freq.shape[0] in (1, self.n_channels)\n",
    "            if freq.shape[0] != self.n_channels:\n",
    "                freq = freq.repeat(self.n_channels)\n",
    "            self.register_buffer('_freq', freq)\n",
    "    \n",
    "\n",
    "    def _create_parameters_bandwidth(self, n_coef, seed):\n",
    "        \n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(seed+1)\n",
    "        coef = torch.rand(size=(n_coef,), generator=generator) * self.margin_bandwidth\n",
    "        \n",
    "        return coef\n",
    "\n",
    "    def _create_parameters_fmin(self, n_coef, seed):\n",
    "        \n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(seed+1)\n",
    "        coef = torch.rand(size=(n_coef,), generator=generator)*self.fmin_variety+self.margin_fmin\n",
    "        \n",
    "        return coef\n",
    "    \n",
    "    def _create_frequencies(self):\n",
    "        \n",
    "        if self.bandwidth is None:\n",
    "            bandwidth = self.coef_bandwidth\n",
    "        else:\n",
    "            bandwidth = self._bandwidth\n",
    "            \n",
    "        if self.fmin is None:\n",
    "            fmin = self.coef_fmin\n",
    "        else:\n",
    "            fmin = self._fmin\n",
    "\n",
    "\n",
    "        if self.freq != None:\n",
    "            freq = self._freq\n",
    "        else:\n",
    "            freq = fmin + bandwidth/2\n",
    "\n",
    "        freq_low = fmin\n",
    "        freq_high = fmin + bandwidth\n",
    "\n",
    "        return bandwidth, freq_low, freq_high, freq\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc58ba-a005-4e18-99cf-8bb81b6dc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SincLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='1d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)\n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,-1)))\n",
    "\n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1)), freq_high.reshape((-1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * _scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * _scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "    \n",
    "                                     \n",
    "class SincLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)         \n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,1,-1)))\n",
    "                                     \n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1,1)), freq_high.reshape((-1,1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * _scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * _scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "                                     \n",
    "    \n",
    "    \n",
    "    \n",
    "class SincHilbertLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='1d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=True)   \n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,-1)))\n",
    "        self.hilbert = HilbertLayer()\n",
    "\n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1)), freq_high.reshape((-1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * _scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * _scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            \n",
    "        if not return_filtered:\n",
    "            x = self.hilbert(x)\n",
    "            x = torch.abs(x)\n",
    "        x = x[...,self.pad.padding_hilbert:-self.pad.padding_hilbert]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SincHilbertLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=True)\n",
    "        self.register_buffer('_hamming_window', torch.hamming_window(kernel_size).reshape((1,1,-1)))\n",
    "        self.hilbert = HilbertLayer()\n",
    "\n",
    "    def _create_filters(self, freq_low, freq_high):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq_low, freq_high = freq_low.reshape((-1,1,1,1)), freq_high.reshape((-1,1,1,1))   \n",
    "        filt_low = freq_low * torch.special.sinc(2 * freq_low * self._scale)\n",
    "        filt_high = freq_high * torch.special.sinc(2 * freq_high * self._scale)\n",
    "        filt = self._hamming_window * 2 * (filt_high - filt_low) / self.srate\n",
    "        return filt\n",
    "        \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        _, _, freq_low, freq_high = self._create_frequencies()\n",
    "        filt = self._create_filters(freq_low, freq_high)\n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            \n",
    "        if not return_filtered:\n",
    "            x = self.hilbert(x)\n",
    "            x = torch.abs(x)\n",
    "        x = x[...,self.pad.padding_hilbert:-self.pad.padding_hilbert]\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class WaveletLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)     \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1)), bandwidth.reshape((-1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * torch.cos(2*math.pi * freq * _scale)\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "                            \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "\n",
    "    \n",
    "class WaveletLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)     \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1,1)), bandwidth.reshape((-1,1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * torch.cos(2*math.pi * freq * _scale)\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "                            \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class ComplexWaveletLayer1d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='1d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)    \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1)), bandwidth.reshape((-1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * (torch.exp(1j*2*math.pi * freq * _scale) - torch.exp(-0.5*(2*math.pi * freq)**2))\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "          \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        assert self.in_channels == x.shape[-2]\n",
    "        \n",
    "        if return_filtered:\n",
    "            x = F.conv1d(x, filt.real, groups=self.in_channels, padding='valid')\n",
    "        else:\n",
    "            x = x.to(torch.complex64)\n",
    "            x = F.conv1d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            x = torch.abs(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ComplexWaveletLayer2d(TemporalFilter):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, srate, fmin_init, fmax_init, freq=None, bandwidth=None, padding_mode='zeros', seed=None):\n",
    "        super().__init__(out_channels, kernel_size, srate, fmin_init, fmax_init, freq, bandwidth, seed=seed)\n",
    "        self.in_channels = in_channels\n",
    "        self.pad = TemporalPad(padding='same', dim='2d', kernel_size=kernel_size, padding_mode=padding_mode, hilbert=False)    \n",
    "           \n",
    "    def _create_filters(self, freq, bandwidth):\n",
    "        _scale = self._scale.reshape((1,1,1,-1))\n",
    "        freq, bandwidth = freq.reshape((-1,1,1,1)), bandwidth.reshape((-1,1,1,1))\n",
    "        sigma2 = (2 * math.log(2)) / (bandwidth * math.pi)**2\n",
    "        filt = (2 * math.pi * sigma2)**(-1/2) / (self.srate / 2)\n",
    "        filt = filt * (torch.exp(1j*2*math.pi * freq * _scale) - torch.exp(-0.5*(2*math.pi * freq)**2))\n",
    "        filt = filt * torch.exp(- _scale**2 / (2 * sigma2))\n",
    "        return filt\n",
    "          \n",
    "    def forward(self, x, return_filtered=False):\n",
    "        x = self.pad(x)\n",
    "        freq, bandwidth, _, _ = self._create_frequencies()\n",
    "        filt = self._create_filters(freq, bandwidth)\n",
    "        \n",
    "        assert self.in_channels == x.shape[-3]\n",
    "        if return_filtered:\n",
    "            x = F.conv2d(x, filt.real, groups=self.in_channels, padding='valid')\n",
    "        else:\n",
    "            x = x.to(torch.complex64)\n",
    "            x = F.conv2d(x, filt, groups=self.in_channels, padding='valid')\n",
    "            x = torch.abs(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
